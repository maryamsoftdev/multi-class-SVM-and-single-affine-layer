# -*- coding: utf-8 -*-
"""multi class SVM and single affine layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HFoiwwg1m7VJJypXhylDlHlj5c6bDz4x
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

class SingleLayerNeuralNetwork:
    def __init__(self, input_size, output_size):
        self.weights = np.random.randn(input_size, output_size)
        self.bias = np.zeros(output_size)

    def train(self, X_train, y_train, learning_rate=0.01, reg_strength=0.01, epochs=1000):
        num_samples = X_train.shape[0]

        for epoch in range(epochs):
            # Forward pass
            scores = np.dot(X_train, self.weights) + self.bias

            # Compute SVM loss
            correct_scores = scores[np.arange(num_samples), y_train]
            margins = np.maximum(0, scores - correct_scores[:, np.newaxis] + 1)
            margins[np.arange(num_samples), y_train] = 0
            loss = np.mean(np.sum(margins, axis=1)) / num_samples

            # Add regularization to the loss
            loss += 0.5 * reg_strength * np.sum(self.weights * self.weights)

            # Backpropagation
            margins[margins > 0] = 1
            row_sum = np.sum(margins, axis=1)
            margins[np.arange(num_samples), y_train] = -row_sum
            dW = np.dot(X_train.T, margins)
            db = np.sum(margins, axis=0)

            # Gradient descent update
            self.weights -= learning_rate * (dW / num_samples + reg_strength * self.weights)
            self.bias -= learning_rate * db / num_samples

            if epoch % 100 == 0:
                train_loss = loss
                train_accuracy = accuracy_score(y_train, np.argmax(scores, axis=1))
                print(f"Epoch {epoch}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy:.4f}")

    def predict(self, X):
        scores = np.dot(X, self.weights) + self.bias
        return np.argmax(scores, axis=1)

def main():
    # Load Iris dataset
    iris = load_iris()
    X, y = iris.data, iris.target

    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Define and train the single layer neural network
    num_features = X_train.shape[1]
    num_classes = len(np.unique(y))
    neural_network = SingleLayerNeuralNetwork(num_features, num_classes)
    neural_network.train(X_train, y_train)

    # Make predictions on the test set
    y_pred = neural_network.predict(X_test)

    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print("Test Accuracy:", accuracy)

if __name__ == "__main__":
    main()